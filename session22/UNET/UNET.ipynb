{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import imageio\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData (path1, path2):\n",
    "    \"\"\"\n",
    "    Looks for relevant filenames in the shared path\n",
    "    Returns 2 lists for original and masked files respectively\n",
    "\n",
    "    \"\"\"\n",
    "    # Read the images folder like a list\n",
    "    image_dataset = os.listdir(path1)\n",
    "    mask_dataset = os.listdir(path2)\n",
    "\n",
    "    # Make a list for images and masks filenames\n",
    "    orig_img = []\n",
    "    mask_img = []\n",
    "    for file in image_dataset:\n",
    "        orig_img.append(file)\n",
    "    for file in mask_dataset:\n",
    "        mask_img.append(file)\n",
    "\n",
    "    # Sort the lists to get both of them in same order (the dataset has exactly the same name for images and corresponding masks)\n",
    "    orig_img.sort()\n",
    "    mask_img.sort()\n",
    "\n",
    "    return orig_img, mask_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreprocessData(img, mask, target_shape_img, target_shape_mask, path1, path2):\n",
    "    \"\"\"\n",
    "    Processes the images and mask present in the shared list and path\n",
    "    Returns a NumPy dataset with images as 3-D arrays of desired size\n",
    "    Please note the masks in this dataset have only one channel\n",
    "    \"\"\"\n",
    "    # Pull the relevant dimensions for image and mask\n",
    "    m = len(img)                     # number of images\n",
    "    i_h,i_w,i_c = target_shape_img   # pull height, width, and channels of image\n",
    "    m_h,m_w,m_c = target_shape_mask  # pull height, width, and channels of mask\n",
    "\n",
    "    # Define X and Y as number of images along with shape of one image\n",
    "    X = np.zeros((m,i_h,i_w,i_c), dtype=np.float32)\n",
    "    y = np.zeros((m,m_h,m_w,m_c), dtype=np.int32)\n",
    "\n",
    "    # Resize images and masks\n",
    "    for file in img:\n",
    "        # convert image into an array of desired shape (3 channels)\n",
    "        index = img.index(file)\n",
    "        path = os.path.join(path1, file)\n",
    "        single_img = Image.open(path).convert('RGB')\n",
    "        single_img = single_img.resize((i_h,i_w))\n",
    "        single_img = np.reshape(single_img,(i_h,i_w,i_c))\n",
    "        single_img = single_img/256.\n",
    "        X[index] = single_img\n",
    "\n",
    "        # convert mask into an array of desired shape (1 channel)\n",
    "        single_mask_ind = mask[index]\n",
    "        path = os.path.join(path2, single_mask_ind)\n",
    "        single_mask = Image.open(path)\n",
    "        single_mask = single_mask.resize((m_h, m_w))\n",
    "        single_mask = np.reshape(single_mask,(m_h,m_w,m_c))\n",
    "        single_mask = single_mask - 1 # to ensure classes #s start from 0\n",
    "        y[index] = single_mask\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '/content/drive/MyDrive/ERA_V2/Assignment21_unet/data/train_images/'\n",
    "path2 = '/content/drive/MyDrive/ERA_V2/Assignment21_unet/data/train_masks/'\n",
    "\n",
    "img, mask = LoadData (path1, path2)\n",
    "\n",
    "show_images = 1\n",
    "for i in range(show_images):\n",
    "    img_view  = imageio.imread(path1 + img[i])\n",
    "    mask_view = imageio.imread(path2 + mask[i])\n",
    "    print(img_view.shape)\n",
    "    print(mask_view.shape)\n",
    "    fig, arr = plt.subplots(1, 2, figsize=(15, 15))\n",
    "    arr[0].imshow(img_view)\n",
    "    arr[0].set_title('Image '+ str(i))\n",
    "    arr[1].imshow(mask_view)\n",
    "    arr[1].set_title('Masked Image '+ str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired shape\n",
    "target_shape_img = [128, 128, 3]\n",
    "target_shape_mask = [128, 128, 1]\n",
    "\n",
    "# Process data using apt helper function\n",
    "X, y = PreprocessData(img, mask, target_shape_img, target_shape_mask, path1, path2)\n",
    "\n",
    "# QC the shape of output and classes in output dataset\n",
    "print(\"X Shape:\", X.shape)\n",
    "print(\"Y shape:\", y.shape)\n",
    "# There are 1 classes : background, pet, outline\n",
    "print(np.unique(y))\n",
    "\n",
    "# Visualize the output\n",
    "image_index = 0\n",
    "fig, arr = plt.subplots(1, 2, figsize=(15, 15))\n",
    "arr[0].imshow(X[image_index])\n",
    "arr[0].set_title('Processed Image')\n",
    "arr[1].imshow(y[image_index,:,:,0])\n",
    "arr[1].set_title('Processed Masked Image ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "# Custom Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, masks, transform=None):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            #mask = self.transform(mask)\n",
    "\n",
    "        #image = np.expand_dims(image, axis=0)  # Add channel dimension\n",
    "        #mask = np.expand_dims(mask, axis=0)    # Add channel dimension\n",
    "        mask = mask.squeeze()  # Remove channel dimension\n",
    "\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "# Parameters\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "num_epochs = 25\n",
    "\n",
    "# Transformations (if needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize image\n",
    "])\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = CustomDataset(images=X_train, masks=y_train, transform=transform)\n",
    "valid_dataset = CustomDataset(images=X_valid, masks=y_valid, transform=transform)\n",
    "\n",
    "# Create Data Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "     \n",
    "\n",
    "# Define the UNet architecture\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# Instantiate the model, criterion, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet().to(device)\n",
    "# Use binary cross entropy loss since the output is a single channel mask\n",
    "criterion = nn.BCEWithLogitsLoss() # Changed loss function for single channel output\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, masks in train_loader:\n",
    "            inputs, masks = inputs.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # Sigmoid activation to get probabilities\n",
    "            outputs = torch.sigmoid(outputs) # Added sigmoid activation\n",
    "            # Ensure masks have the same spatial dimensions as the model output\n",
    "            masks = F.interpolate(masks.unsqueeze(1), size=outputs.shape[2:], mode='nearest') # Added interpolation\n",
    "            # Flatten the target mask and output to calculate loss\n",
    "            loss = criterion(outputs.view(-1), masks.view(-1)) # Modified loss calculation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, masks in valid_loader:\n",
    "                inputs, masks = inputs.to(device), masks.to(device)\n",
    "                outputs = model(inputs)\n",
    "                # Sigmoid activation for validation as well\n",
    "                outputs = torch.sigmoid(outputs) # Added sigmoid activation\n",
    "                # Ensure masks have the same spatial dimensions for validation\n",
    "                masks = F.interpolate(masks.unsqueeze(1), size=outputs.shape[2:], mode='nearest') # Added interpolation\n",
    "                # Flatten for validation loss calculation\n",
    "                loss = criterion(outputs.view(-1), masks.view(-1)) # Modified loss calculation\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        val_loss /= len(valid_loader.dataset)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
